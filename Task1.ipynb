{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e47584ee-ecdf-4c96-a69e-879230545b0c",
   "metadata": {},
   "source": [
    "# Task-1\n",
    "\n",
    "## Complete the missing code for the GEOMETRY model below according to the paper. \n",
    "\n",
    "LipSync3D: Data-Efficient Learning of Personalized 3D Talking Faces from Video using Pose and Lighting Normalization https://arxiv.org/abs/2106.04185"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17288082-33ab-4991-9d97-f2f96d72ca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Referred https://github.com/longredzhong/LipSync3D/blob/master/lipsync3d/model.py\n",
    "class View(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super(View, self).__init__()\n",
    "        self.shape = shape\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x.view(*self.shape)\n",
    "\n",
    "class Geometry_Model(nn.Module):\n",
    "    \"\"\"Model comprising of an audio encoder and geometry decoder\"\"\"\n",
    "    \n",
    "    def __init__(self, Ns):\n",
    "        super(Geometry_Model, self).__init__()\n",
    "        self.Ns = Ns\n",
    "        \"\"\"Audio encoder \n",
    "        We directly use complex spectrograms St. \n",
    "        Each St tensor is passed through a 12 layer deep encoder network where \n",
    "        the first 6 layers apply 1D convolutions over frequencies (kernel 3 × 1, stride 2 × 1)\n",
    "        the subsequent 6 layers apply 1D convolution over time (kernel 1 × 3, stride 1 × 2)\n",
    "        All with leaky ReLU activation\n",
    "\n",
    "        We used hyperparameter search to determine the latent code lengths, Ns = 32 \n",
    "        \n",
    "        Input: takes in audio spectogram of shape B x 2 x 256 x 24\n",
    "        Output: a vector of shape B * Ns ; \n",
    "        \"\"\"\n",
    "        # Referred to https://github.com/leventt/surat/blob/master/surat.py for the parent paper model\n",
    "        # We basically adopt the output channels at each layer from this paper. Kernel and stride are \n",
    "        # the values mentioned in our paper\n",
    "        self.audio_encoder = nn.Sequential(\n",
    "            #Convolution over frequencies\n",
    "            # 2 x 256 x 24 -> 72 x 128 x 24\n",
    "            nn.Conv2d(2, 72, (3, 1), (2, 1), (1, 0)),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            # 72 x 128 x 24 -> 108 x 64 x 24\n",
    "            nn.Conv2d(72, 108, (3, 1), (2, 1), (1, 0)),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            # 108 x 64 x 24 -> 162 x 32 x 24\n",
    "            nn.Conv2d(108, 162, (3, 1), (2, 1), (1, 0)),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            # 162 x 32 x 24 -> 243 x 16 x 24\n",
    "            nn.Conv2d(162, 243, (3, 1), (2, 1), (1, 0)),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            # 243 x 16 x 24 -> 256 x 8 x 24\n",
    "            nn.Conv2d(243, 256, (3, 1), (2, 1), (1, 0)),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            # 256 x 8 x 24 -> 256 x 4 x 24\n",
    "            nn.Conv2d(256, 256, (3, 1), (2, 1), (1, 0)),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            # Convolution over time\n",
    "            # 256 x 4 x 24 -> 128 x 4 x 13\n",
    "            nn.Conv2d(256, 128, (1, 3), (1, 2), (0, 2)),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            # 128 x 4 x 13 -> 64 x 4 x 8\n",
    "            nn.Conv2d(128, 64, (1, 3), (1, 2), (0, 2)),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            # 64 x 4 x 8 -> 32 x 4 x 5\n",
    "            nn.Conv2d(64, 32, (1, 3), (1, 2), (0, 2)),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            # 32 x 4 x 5 -> 16 x 4 x 4\n",
    "            nn.Conv2d(32, 16, (1, 3), (1, 2), (0, 2)),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            # 16 x 4 x 4 -> 8 x 4 x 3\n",
    "            nn.Conv2d(16, 8, (1, 3), (1, 2), (0, 2)),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            # 8 x 4 x 3 -> 4 x 4 x 2\n",
    "            nn.Conv2d(8, 4, (1, 3), (1, 2), (0, 1)),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            # 4 x 4 x 2 -> 1 x Ns\n",
    "            View([-1, self.Ns])\n",
    "        )\n",
    "\n",
    "        \"\"\"Geometry Decoder \n",
    "        Maps the latent code from the audio encoder to the vertex deformations\n",
    "        It consists of two fully connected layers with 150 and 1404 units\n",
    "        and linear activations, with a dropout layer in the middle. \n",
    "        The resulting output is 468 vertices (1404 = 468 * 3)\n",
    "        \n",
    "        Input: Takes in the latent vector audio encoder outputs of shape B * 32\n",
    "        Output: a vector of shape B * 1404\n",
    "        \"\"\"\n",
    "        self.geometry_decoder = nn.Sequential(\n",
    "            nn.Linear(self.Ns, 150),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(150, 1404))\n",
    "\n",
    "    def forward(self, audio_spectogram):\n",
    "        \"\"\"\n",
    "        forward pass takes in the audio spectogram, \n",
    "        encodes the spectogram into latent code\n",
    "        decodes it to output the number of vertices required\n",
    "        \"\"\"\n",
    "        # spectogram : B x 2 x 256 x 24\n",
    "        latent = self.audio_encoder(audio_spectogram)\n",
    "        vertices = self.geometry_decoder(latent)\n",
    "        \n",
    "        return vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2927939f-8a5b-4fa1-895b-38ffa8d65385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Geometry_Model                           [16, 1404]                --\n",
       "├─Sequential: 1-1                        [16, 32]                  --\n",
       "│    └─Conv2d: 2-1                       [16, 72, 128, 24]         504\n",
       "│    └─LeakyReLU: 2-2                    [16, 72, 128, 24]         --\n",
       "│    └─Conv2d: 2-3                       [16, 108, 64, 24]         23,436\n",
       "│    └─LeakyReLU: 2-4                    [16, 108, 64, 24]         --\n",
       "│    └─Conv2d: 2-5                       [16, 162, 32, 24]         52,650\n",
       "│    └─LeakyReLU: 2-6                    [16, 162, 32, 24]         --\n",
       "│    └─Conv2d: 2-7                       [16, 243, 16, 24]         118,341\n",
       "│    └─LeakyReLU: 2-8                    [16, 243, 16, 24]         --\n",
       "│    └─Conv2d: 2-9                       [16, 256, 8, 24]          186,880\n",
       "│    └─LeakyReLU: 2-10                   [16, 256, 8, 24]          --\n",
       "│    └─Conv2d: 2-11                      [16, 256, 4, 24]          196,864\n",
       "│    └─LeakyReLU: 2-12                   [16, 256, 4, 24]          --\n",
       "│    └─Conv2d: 2-13                      [16, 128, 4, 13]          98,432\n",
       "│    └─LeakyReLU: 2-14                   [16, 128, 4, 13]          --\n",
       "│    └─Conv2d: 2-15                      [16, 64, 4, 8]            24,640\n",
       "│    └─LeakyReLU: 2-16                   [16, 64, 4, 8]            --\n",
       "│    └─Conv2d: 2-17                      [16, 32, 4, 5]            6,176\n",
       "│    └─LeakyReLU: 2-18                   [16, 32, 4, 5]            --\n",
       "│    └─Conv2d: 2-19                      [16, 16, 4, 4]            1,552\n",
       "│    └─LeakyReLU: 2-20                   [16, 16, 4, 4]            --\n",
       "│    └─Conv2d: 2-21                      [16, 8, 4, 3]             392\n",
       "│    └─LeakyReLU: 2-22                   [16, 8, 4, 3]             --\n",
       "│    └─Conv2d: 2-23                      [16, 4, 4, 2]             100\n",
       "│    └─LeakyReLU: 2-24                   [16, 4, 4, 2]             --\n",
       "│    └─View: 2-25                        [16, 32]                  --\n",
       "├─Sequential: 1-2                        [16, 1404]                --\n",
       "│    └─Linear: 2-26                      [16, 150]                 4,950\n",
       "│    └─Dropout: 2-27                     [16, 150]                 --\n",
       "│    └─Linear: 2-28                      [16, 1404]                212,004\n",
       "==========================================================================================\n",
       "Total params: 926,921\n",
       "Trainable params: 926,921\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 2.95\n",
       "==========================================================================================\n",
       "Input size (MB): 0.79\n",
       "Forward/backward pass size (MB): 88.30\n",
       "Params size (MB): 3.71\n",
       "Estimated Total Size (MB): 92.79\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install torchinfo\n",
    "from torchinfo import summary\n",
    "\n",
    "# We used hyperparameter search to determine the latent code lengths, Ns = 32\n",
    "model = Geometry_Model(32)\n",
    "batch_size = 16\n",
    "summary(model, input_size=(batch_size, 2, 256, 24))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
