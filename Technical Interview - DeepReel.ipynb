{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task-1\n",
    "\n",
    "## Complete the missing code for the GEOMETRY model below according to the paper. \n",
    "\n",
    "LipSync3D: Data-Efficient Learning of Personalized 3D Talking Faces from Video using Pose and Lighting Normalization https://arxiv.org/abs/2106.04185"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Geometry_Model(nn.Module):\n",
    "    \"\"\"\n",
    "    Model comprising of an audio encoder and geometry decoder\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Geometry_Model, self).__init__()\n",
    "        \"\"\"\n",
    "        audio encoder \n",
    "        input: ?\n",
    "        \n",
    "        output: ?\n",
    "        \"\"\"\n",
    "        self.audio_encoder = nn.Sequential(\n",
    "        ############ TODO: IMPLEMENT THE ENCODER MODEL #################\n",
    "        )\n",
    "        \"\"\"\n",
    "        Geometry Decoder maps the latent code from the audio encoder to the vertex deformations\n",
    "        input: ?\n",
    "        Output: ?\n",
    "        \"\"\"\n",
    "        self.geometry_decoder = nn.Sequential(\n",
    "        ############ TODO: IMPLEMENT THE DECODER MODEL #################\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, audio_spectogram):\n",
    "        \"\"\"\n",
    "        forward pass takes in the audio spectogram, \n",
    "        encodes the spectogram into latent code\n",
    "        decodes it to output the number of vertices required\n",
    "        \"\"\"\n",
    "        ############ TODO: IMPLEMENT THE FORWARD PASS #################\n",
    "        \n",
    "        return vertices\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK-2 \n",
    "### Implement the pose normalisation of reference mesh from the following section (3.1.1) quoted in the paper:\n",
    "\n",
    "\"Using the reference vertices, we define a reference cylindrical coordinate system (similar to [4]) \n",
    "with a vertical axis such that most face vertices are equidistant to the axis. \n",
    "We then scale the face size such that the eyes and nose project to fixed locations on this reference cylinder.\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ TODO: IMPLEMENT POSE NORMALISATION OF THE REFERENCE MESH #################\n",
    "\n",
    "'''\n",
    "Using the first 468 vertices of the reference mesh, implement the following section quoted \n",
    "from the LipSync3d paper:\n",
    "\n",
    "Using the reference vertices, we define a reference cylindrical coordinate system (similar to [4]) \n",
    "with a vertical axis such that most face vertices are equidistant to the axis. \n",
    "We then scale the face size such that the eyes and nose project to fixed locations on this reference cylinder.\n",
    "\n",
    "'''\n",
    "# !pip install mediapipe\n",
    "\n",
    "import mediapipe.python.solutions.face_mesh as mp_face_mesh\n",
    "import mediapipe.python.solutions.drawing_utils as mp_drawing\n",
    "import mediapipe.python.solutions.drawing_styles as mp_drawing_styles\n",
    "import cv2\n",
    "\n",
    "## Additional imports for aux functions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper function for converting Landmarks to dict\n",
    "def landmark_to_dict(landmark_list):\n",
    "    landmark_dict = {}\n",
    "    for idx, landmark in enumerate(landmark_list):\n",
    "        landmark_dict[idx] = [landmark.x, landmark.y, landmark.z]\n",
    "\n",
    "    return landmark_dict\n",
    "\n",
    "# Convert Landmark dict to np.array\n",
    "def dict_to_pcd(landmark_dict):\n",
    "    reference_mesh = np.empty((0,3), int)\n",
    "    for i in range(len(reference_dict)):\n",
    "        row = np.array(reference_dict[i])\n",
    "        reference_mesh = np.vstack([reference_mesh,row])\n",
    "    return reference_mesh\n",
    "\n",
    "# Convert pcd to dict\n",
    "def pcd_to_dict(pcd):\n",
    "    landmark_dict = {}\n",
    "    for idx, landmark in enumerate(pcd):\n",
    "        landmark_dict[idx] = list(landmark)\n",
    "\n",
    "    return landmark_dict\n",
    "\n",
    "# Convert cylindrical coords array to cartesian coords array\n",
    "def cyl2cart(cy_coords, radius):\n",
    "    cart_coords = np.zeros_like(cy_coords)\n",
    "    # element wise multiply \n",
    "    cart_coords[:, 0] = (cy_coords[:, 2] + radius)*np.sin(cy_coords[:, 0] / radius)\n",
    "    cart_coords[:, 2] = (cy_coords[:, 2] + radius)*np.cos(cy_coords[:, 0] / radius)\n",
    "    cart_coords[:, 1] = cy_coords[:, 1]\n",
    "    return cart_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3D Plotter helper function\n",
    "def plotTessMesh(dict, title):\n",
    "    connections = mp_face_mesh.FACEMESH_TESSELATION\n",
    "    drawing_spec = mp_drawing.DrawingSpec(color= mp_drawing.BLACK_COLOR, thickness=1, circle_radius=1)\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    ax = plt.axes(projection='3d')\n",
    "    ax.view_init(elev=10, azim=10)\n",
    "    plotted_landmarks = {}\n",
    "    \n",
    "    for idx, coord in dict.items():\n",
    "        if (idx == 'R') or (idx == 't') or (idx == 'c'):\n",
    "            continue\n",
    "        plotted_landmarks[idx] = (-coord[2], coord[0], -coord[1])\n",
    "    \n",
    "    for connection in connections:\n",
    "        start_idx = connection[0]\n",
    "        end_idx = connection[1]\n",
    "    \n",
    "        if start_idx in plotted_landmarks and end_idx in plotted_landmarks:\n",
    "            landmark_pair = [plotted_landmarks[start_idx], plotted_landmarks[end_idx]]\n",
    "            ax.plot3D(\n",
    "                xs=[landmark_pair[0][0], landmark_pair[1][0]],\n",
    "                ys=[landmark_pair[0][1], landmark_pair[1][1]],\n",
    "                zs=[landmark_pair[0][2], landmark_pair[1][2]],\n",
    "                color=(0., 0., 1.),\n",
    "                linewidth=1)\n",
    "\n",
    "    %matplotlib inline\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reading in face data and extracting 3D landmarks\n",
    "IMAGE_PATH = 'reference_frame.jpg' # Change the image path to the provided image \n",
    "image = cv2.imread(IMAGE_PATH)\n",
    "image_rows, image_cols, _ = image.shape\n",
    "\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=True,\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5) as face_mesh:\n",
    "\n",
    "    results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    reference_dict = landmark_to_dict(results.multi_face_landmarks[0].landmark)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert landmark keypoints to numpy array\n",
    "reference_mesh = np.empty((0,3), int)\n",
    "for i in range(len(reference_dict)):\n",
    "    row = np.array(reference_dict[i])\n",
    "    reference_mesh = np.vstack([reference_mesh,row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTessMesh(reference_dict, 'Original Mesh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 3\n",
    "## Parallel Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "You have an image manipulation method \"preprocess()\" defined below that you want to apply to a list of images \n",
    "of dimensions (Height, Width, Channels).\n",
    "Your task is to change the code such that it processes the images faster using \"multi-processing\" that utilises\n",
    "all the cores of the CPU\n",
    "\n",
    "\"\"\"\n",
    "# !pip install scikit-image\n",
    "import random\n",
    "random.seed(0)\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import time\n",
    "\n",
    "\n",
    "# Randomly produced RGB images\n",
    "image_list = []\n",
    "for i in range(10):\n",
    "    image_list.append(np.random.randint(1,100, size=(128,128,3)))\n",
    "\n",
    "\n",
    "\n",
    "def preprocess(image):\n",
    "    sigma = 3.0\n",
    "\n",
    "    # apply Gaussian blur, creating a new image\n",
    "    blurred = skimage.filters.gaussian(\n",
    "        image, sigma=(sigma, sigma), truncate=3.5, multichannel=True)\n",
    "    return blurred\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "################# MODIFY YOUR CODE HERE #####################\n",
    "\n",
    "\n",
    "\n",
    "blurred_images = []\n",
    "for i in range(len(image_list)):\n",
    "    blurred_images.append(preprocess(image_list[i]))\n",
    "\n",
    "\n",
    "          \n",
    "#############################################################       \n",
    "        \n",
    "        \n",
    "# get the end time\n",
    "end = time.time()\n",
    "\n",
    "# get the execution time\n",
    "elapsed_time = end - start\n",
    "print('Execution time:', elapsed_time, 'seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
